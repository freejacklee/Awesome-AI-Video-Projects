仓库地址：* [freejacklee/Awesome-AI-Video-Projects: This is an awesome GitHub list of information about the current collection of AI video projects] https://github.com/freejacklee/Awesome-AI-Video-Projects

提交内容：List  about the current collection of AI video projects.md



This is an awesome GitHub list of information about the current collection of AI video projects

List  about the current collection of AI video projects



## 元资源

* [Text-to-video model - Wikipedia --- 文本到视频模型 - 维基百科](https://en.wikipedia.org/wiki/Text-to-video_model)

  * A **text-to-video model** is a [machine learning](https://en.wikipedia.org/wiki/Machine_learning) model which takes as input a [natural language](https://en.wikipedia.org/wiki/Natural_language) description and produces a [video](https://en.wikipedia.org/wiki/Video) matching that description.[[1\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-AIIR-1)
    文本到视频模型是一种机器学习模型，它将自然语言描述作为输入并生成与该描述匹配的视频。 [[1\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-AIIR-1)

    Video prediction on making objects realistic in a stable background is performed by using [recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network) for a sequence to sequence model with a connector [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) encoding and decoding each frame pixel by pixel,[[2\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-2) creating video using [deep learning](https://en.wikipedia.org/wiki/Deep_learning).[[3\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-3)
    通过使用循环神经网络进行序列到序列模型的视频预测，使对象在稳定的背景下具有连接器卷积神经网络逐像素编码和解码每个帧， [[2\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-2) 使用深度学习创建视频。 [[3\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-3)

* [Generative artificial intelligence - Wikipedia --- 生成人工智能 - 维基百科](https://en.wikipedia.org/wiki/Generative_artificial_intelligence)
  * Video 视频
    * Generative AI trained on annotated video can generate temporally-coherent video clips. Examples include Gen-1 and Gen-2 by [Runway](https://en.wikipedia.org/wiki/Runway_(company))[[44\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-44) and Make-A-Video by Meta Platforms.[[45\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-45)
      经过带注释视频训练的生成式人工智能可以生成时间连贯的视频剪辑。示例包括 Runway [[44\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-44) 的 Gen-1 和 Gen-2 以及 Meta Platforms 的 Make-A-Video。 [[45\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-45)



AI generated video tool

1、Pika

Website: https://pika.art 
Discord: http://discord.gg/pika 
About: https://pika.art/about

* [AI生成视频工具Pika爆火，估值超2亿美元-虎嗅网](https://m.huxiu.com/article/2361484.html#:~:text=%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%8D%8E%E4%BA%BA%E5%AD%A6%E7%94%9F%E9%80%80%E5%AD%A6%E5%88%9B%E5%8A%9E,%E7%BC%96%E8%BE%91%E5%92%8C%E9%87%8D%E6%96%B0%E6%9E%84%E6%83%B3%E5%9C%BA%E6%99%AF%E3%80%82&text=%F0%9F%92%A5%20Pika%201.0%E4%BD%BF%E7%94%A8AI,%E7%AE%80%E5%8D%95%E4%B8%94%E9%A3%8E%E6%A0%BC%E5%A4%9A%E5%8F%98%E3%80%82)
  * 斯坦福华人学生退学创办的AI视频生成工具Pika 1.0正式推出，估值超过2亿美元。 该工具可以通过文字、图片和视频生成高质量的各种风格视频，并且支持用户上传视频片段进行编辑和重新构想场景。 💥 Pika 1.0使用AI模型生成非常贴近生动的视频，使用简单且风格多变。

* [斯坦福华人博士文生视频Pika 1.0爆火，4人公司估值2亿，OpenAI联创参投-36氪](https://36kr.com/p/2539021165094660)

  * Runway Gen-2最强竞品Pika，暌违半年忽然放出大招——Pika 1.0正式发布！

    仅成立六个月，Pika就结束了测试版，正式发布了第一个产品，能够生成和编辑3D动画、动漫、卡通和电影。

* [Pika (@pika\_labs) / X](https://twitter.com/pika_labs)

* [Pika, which is building AI tools to generate and edit videos, raises $55M | TechCrunch --- Pika 正在构建用于生成和编辑视频的 AI 工具，筹集了 5500 万美元 | TechCrunch](https://techcrunch.com/2023/11/28/pika-labs-which-is-building-ai-tools-to-generate-and-edit-videos-raises-55m/)

  

2、Runway Gen-2

Website: https://research.runwayml.com/gen2

Discord: https://discord.com/invite/runwayml

About: https://research.runwayml.com/about

* [What is Gen-2 AI and How to Use It? A Step-by-Step Guide --- 什么是第二代人工智能以及如何使用它？分步指南](https://ambcrypto.com/blog/what-is-gen-2-and-how-to-use-it-a-step-by-step-guide/)

  * Gen-2 AI is the second generation of Runway’s AI software, which focuses on generating videos from scratch using text descriptions, images, or existing video clips. 
    Gen-2 AI 是 Runway 的第二代 AI 软件，专注于使用文本描述、图像或现有视频剪辑从头开始生成视频。

    This cutting-edge technology opens a realm of possibilities for content creators, allowing them to craft distinctive and captivating videos without resorting to costly equipment or lengthy procedures.
    这项尖端技术为内容创作者打开了一个可能性的领域，使他们能够制作独特且引人入胜的视频，而无需诉诸昂贵的设备或冗长的程序。

    The Gen-2 AI model is designed to help users create dreamy videos by harnessing the power of AI and generative algorithms, allowing for an unparalleled level of customization and fidelity in the final output. 
    Gen-2 AI 模型旨在帮助用户利用 AI 和生成算法的力量来创建梦幻视频，从而在最终输出中实现无与伦比的定制化和保真度。

    With Gen-2 AI, the days of being limited by available footage or budget constraints are numbered, as this innovative technology brings endless creative possibilities to the table.
    有了第二代人工智能，受可用镜头或预算限制的日子已经屈指可数了，因为这项创新技术带来了无限的创意可能性。

* [Gen-2颠覆AI生成视频，一句话秒出4K高清大片，网友：彻底改变游戏规则-36氪](https://36kr.com/p/2501983674115975)

* [只要输入一段话就能生成视频？Gen-2实测\_精彩视频为您呈现\_36氪](https://36kr.com/video/2307964668027272)

* [图像涂哪就动哪，Gen-2新功能“神笔马良”爆火，网友：急急急-36氪](https://36kr.com/p/2515454214115330)

* [视频生成AI卷起来了，一句话一张图就能出大片-虎嗅网](https://m.huxiu.com/article/2054357.html)

* [Runway (@runwayml) / X](https://twitter.com/runwayml)

* [Generative AI’s Next Frontier Is Video - Bloomberg --- 生成式人工智能的下一个前沿领域是视频 - Bloomberg](https://www.bloomberg.com/news/articles/2023-03-20/generative-ai-s-next-frontier-is-video)

* [Runway Gen-2 Update Brings Striking Improvements to AI Video Fidelity and Realism --- Runway Gen-2 更新为 AI 视频保真度和真实度带来了显着改进](https://www.maginative.com/article/runway-gen-2-video-ai-takes-major-step-forward-in-fidelity-and-length/)



3、WonderJourney

项目及演示：https://kovenyu.com/wonderjourney/
论文：https://arxiv.org/pdf/2312.03884.pdf
GitHub：https://github.com/KovenYu/WonderJourney（Coming soon!）

WonderJourney：是一个由斯坦福大学和谷歌合作开发的项目。

它能够根据用户提供的文本描述或图片，**自动生成一系列3D场景的连续画面。**

这些场景不仅多样化，而且**彼此之间还能紧密衔接**，形成一种**虚拟的“奇妙旅程”场景**。

**而且你只需要输入一段描述或上传一张图片即可...**



**主要功能特点：**

与之前专注于单一场景类型的视图生成工作不同，WonderJourney从任何用户提供的位置（通过文本描述或图像）开始，生成一系列多样化但连贯相连的3D场景。

**1、从任意位置出发：**用户可以通过提供一段文本描述或一张图片来指定一个起始点。基于这个起始点WonderJourney将生成一系列3D场景。

例如，如果用户上传一张森林的图片或描述一个城市景观，WonderJourney会从这个场景开始，创造一连串与之相关的3D场景。

**2、长时间的“奇妙之旅”：**WonderJourney能够生成不仅多样化而且持续较长时间的3D场景序列。

用户可以体验一段长时间的虚拟旅程，其中场景会连续不断地变化，提供丰富的视觉体验。

**3、多样化的目的地：**即使从同一个起始点出发，WonderJourney也能生成通往不同“目的地”的多条“奇妙之旅”。

例如，从同一张森林图片出发，一条旅程可能以山脉为终点，而另一条可能以海滩结束，展现出不同的场景和风格。

**4、受控的“奇妙之旅”：**用户可以通过提供一系列文本描述（如诗歌、俳句或故事摘要）来指导生成的旅程。

这允许用户创造更具个性和主题性的旅程。例如，根据一首诗的情感和意象，生成一系列与之相匹配的场景。



**工作原理：**

该框架利用大语言模型（LLM）生成场景的文本描述，一个由文本驱动的点云生成管道来制作引人入胜且连贯的3D场景序列，以及一个视觉语言模型（VLM）来验证生成的场景。

1、场景描述生成：使用大型语言模型（LLM）自动生成场景描述。根据用户输入的文本或图像，LLM提供场景的语义和概念描述。

2、文本驱动的视觉场景生成：根据LLM生成的场景描述，使用文本驱动的视觉场景生成模块创建3D场景。该模块将文本描述转换为彩色点云，形成3D场景。

3、视觉验证：使用视觉语言模型（VLM）对生成的场景进行检查。确保场景没有不希望的视觉效果，如视觉上的错误或不连贯性。

4、连贯性和多样性：生成的3D场景在视觉上连贯，同时在风格和类型上多样化。形成一种连续的视觉旅程，模拟在一个虚拟“奇妙世界”中的体验。

* [小互 on X: "WonderJourney：是一个由斯坦福大学和谷歌合作开发的项目。 它能够根据用户提供的文本描述或图片，自动生成一系列3D场景的连续画面。 这些场景不仅多样化，而且彼此之间还能紧密衔接，形成一种虚拟的“奇妙旅程”场景。 而且你只需要输入一段描述或上传一张图片即可... 主要功能特点：… https://t.co/gptrWSyWBz" / X](https://twitter.com/xiaohuggg/status/1733779657722622449)



* [WonderJourney谷歌合作的 3D 场景生成, 带你走进“奇妙旅程”](https://mp.weixin.qq.com/s?search_click_id=12501261693348582618-1702361382506-3224040202&__biz=Mzg2ODk4MDUxOQ==&mid=2247485556&idx=1&sn=b71b69562cab374580961cd61e05b976#rd)
  * 给定诗歌或故事提要等一系列文本描述,WonderJourney也可以生成古诗词场景。



4、



Logging

202312121246 Jack Lee 今天搬运* [OpenMindClub/awesome-chatgpt: ⚡ Everything about ChatGPT --- OpenMindClub/awesome-chatgpt：⚡ 关于 ChatGPT 的一切](https://github.com/OpenMindClub/awesome-chatgpt/tree/main#general)的README.md&README.zh-cn.md文件并稍作初步修改，然后在List  about the current collection of AI video projects.md中继续增加字数，增加了元资源中维基百科文本到视频模型和生成式人工智能，进一步完善了Pika、Gen-2、WonderJourney的介绍 目前字数2562词

202312112138 Jack Lee init 今天完成初稿500字 20000字/42天=477字/天