仓库地址：* [freejacklee/Awesome-AI-Video-Projects: This is an awesome GitHub list of information about the current collection of AI video projects] https://github.com/freejacklee/Awesome-AI-Video-Projects

提交内容：List  about the current collection of AI video projects.md



This is an awesome GitHub list of information about the current collection of AI video projects

List  about the current collection of AI video projects



## 元资源

* [Text-to-video model - Wikipedia --- 文本到视频模型 - 维基百科](https://en.wikipedia.org/wiki/Text-to-video_model)

  * A **text-to-video model** is a [machine learning](https://en.wikipedia.org/wiki/Machine_learning) model which takes as input a [natural language](https://en.wikipedia.org/wiki/Natural_language) description and produces a [video](https://en.wikipedia.org/wiki/Video) matching that description.[[1\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-AIIR-1)
    文本到视频模型是一种机器学习模型，它将自然语言描述作为输入并生成与该描述匹配的视频。 [[1\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-AIIR-1)

    Video prediction on making objects realistic in a stable background is performed by using [recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network) for a sequence to sequence model with a connector [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) encoding and decoding each frame pixel by pixel,[[2\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-2) creating video using [deep learning](https://en.wikipedia.org/wiki/Deep_learning).[[3\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-3)
    通过使用循环神经网络进行序列到序列模型的视频预测，使对象在稳定的背景下具有连接器卷积神经网络逐像素编码和解码每个帧， [[2\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-2) 使用深度学习创建视频。 [[3\]](https://en.wikipedia.org/wiki/Text-to-video_model#cite_note-3)

* [Generative artificial intelligence - Wikipedia --- 生成人工智能 - 维基百科](https://en.wikipedia.org/wiki/Generative_artificial_intelligence)
  * Video 视频
    * Generative AI trained on annotated video can generate temporally-coherent video clips. Examples include Gen-1 and Gen-2 by [Runway](https://en.wikipedia.org/wiki/Runway_(company))[[44\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-44) and Make-A-Video by Meta Platforms.[[45\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-45)
      经过带注释视频训练的生成式人工智能可以生成时间连贯的视频剪辑。示例包括 Runway [[44\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-44) 的 Gen-1 和 Gen-2 以及 Meta Platforms 的 Make-A-Video。 [[45\]](https://en.wikipedia.org/wiki/Generative_artificial_intelligence#cite_note-45)



AI generated video tool

1、Pika

Website: https://pika.art 
Discord: http://discord.gg/pika 
About: https://pika.art/about

个人体验：20231210已申请加入waitlist，暂未获得邀请资格，继续期待。

* [AI生成视频工具Pika爆火，估值超2亿美元-虎嗅网](https://m.huxiu.com/article/2361484.html#:~:text=%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%8D%8E%E4%BA%BA%E5%AD%A6%E7%94%9F%E9%80%80%E5%AD%A6%E5%88%9B%E5%8A%9E,%E7%BC%96%E8%BE%91%E5%92%8C%E9%87%8D%E6%96%B0%E6%9E%84%E6%83%B3%E5%9C%BA%E6%99%AF%E3%80%82&text=%F0%9F%92%A5%20Pika%201.0%E4%BD%BF%E7%94%A8AI,%E7%AE%80%E5%8D%95%E4%B8%94%E9%A3%8E%E6%A0%BC%E5%A4%9A%E5%8F%98%E3%80%82)
  * 斯坦福华人学生退学创办的AI视频生成工具Pika 1.0正式推出，估值超过2亿美元。 该工具可以通过文字、图片和视频生成高质量的各种风格视频，并且支持用户上传视频片段进行编辑和重新构想场景。 💥 Pika 1.0使用AI模型生成非常贴近生动的视频，使用简单且风格多变。

* [斯坦福华人博士文生视频Pika 1.0爆火，4人公司估值2亿，OpenAI联创参投-36氪](https://36kr.com/p/2539021165094660) 

  * [新智元](https://36kr.com/user/574825230)*·*发表于2023-11-29 15:30

  * Runway Gen-2最强竞品Pika，暌违半年忽然放出大招——Pika 1.0正式发布！

    仅成立六个月，Pika就结束了测试版，正式发布了第一个产品，能够生成和编辑3D动画、动漫、卡通和电影。

* [Pika (@pika\_labs) / X](https://twitter.com/pika_labs)

* [Pika, which is building AI tools to generate and edit videos, raises $55M | TechCrunch --- Pika 正在构建用于生成和编辑视频的 AI 工具，筹集了 5500 万美元 | TechCrunch](https://techcrunch.com/2023/11/28/pika-labs-which-is-building-ai-tools-to-generate-and-edit-videos-raises-55m/)

  

2、Runway Gen-2

Website: https://research.runwayml.com/gen2

Discord: https://discord.com/invite/runwayml

About: https://research.runwayml.com/about

Gen-2 Explained：

Not too long ago, runway pushed the boundaries of generative Ai with Gen Onea video to video model that allows you to use words and images to generate new videos out of existing ones in the week since launching, the model has constantly gotten better temporal consistency, better fidelity better results and as more and more people gained access, we unlocked entirely new use cases and displays of creativity and today we're excited to announce our biggest unlock yettext to Video with Gen Two now. You can generate a video with nothing but words, no driving video no input image gen 2 represents yet another major research milestone and another monumental step forward for generative Ai with Gen 2, anyone anywhere can suddenly realize entire worlds, animations stories anything you can imagine gen two coming, very soon to https://runwayml.com/

不久前，runway通过Gen Onea视频到视频模型突破了生成式AI的界限，该模型允许您使用文字和图像从现有视频中生成新视频 自推出以来的一周内，该模型不断获得更好的时间一致性，更好的保真度，更好的结果，并且随着越来越多的人获得访问权限， 我们解锁了全新的用例和创造力展示，今天我们很高兴地宣布，我们迄今为止最大的解锁版本是第二代视频。你可以生成一个只有文字的视频，没有驾驶视频，没有输入图像，第二代代表了另一个重要的研究里程碑，也是生成式人工智能向前迈出的又一重大一步，第二代，任何地方的任何人都可以突然意识到整个世界，动画故事、任何你能想象到的第二代即将到来，很快就会 https://runwayml.com/

个人体验：20231212尝试了一次，用一张弹古筝的女子图片和一句简短的文字生成视频，生成的视频中随着时间流逝人物面部会有点变形。

* [What is Gen-2 AI and How to Use It? A Step-by-Step Guide --- 什么是第二代人工智能以及如何使用它？分步指南](https://ambcrypto.com/blog/what-is-gen-2-and-how-to-use-it-a-step-by-step-guide/)

  * Gen-2 AI is the second generation of Runway’s AI software, which focuses on generating videos from scratch using text descriptions, images, or existing video clips. 
    Gen-2 AI 是 Runway 的第二代 AI 软件，专注于使用文本描述、图像或现有视频剪辑从头开始生成视频。

    This cutting-edge technology opens a realm of possibilities for content creators, allowing them to craft distinctive and captivating videos without resorting to costly equipment or lengthy procedures.
    这项尖端技术为内容创作者打开了一个可能性的领域，使他们能够制作独特且引人入胜的视频，而无需诉诸昂贵的设备或冗长的程序。

    The Gen-2 AI model is designed to help users create dreamy videos by harnessing the power of AI and generative algorithms, allowing for an unparalleled level of customization and fidelity in the final output. 
    Gen-2 AI 模型旨在帮助用户利用 AI 和生成算法的力量来创建梦幻视频，从而在最终输出中实现无与伦比的定制化和保真度。

    With Gen-2 AI, the days of being limited by available footage or budget constraints are numbered, as this innovative technology brings endless creative possibilities to the table.
    有了第二代人工智能，受可用镜头或预算限制的日子已经屈指可数了，因为这项创新技术带来了无限的创意可能性。

* [全面开放，无需排队，Runway视频生成工具Gen-2开启免费试用](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650885185&idx=3&sn=d8042976cd29c23e0c0ba8ee1923a645)
  * Runway 宣布，Gen-1 和 Gen-2 已经彻底开放，任何人都可以注册一个账号免费尝试。生成的视频长度为 4 秒，每秒消耗 5 个积分，利用免费额度可以生成二十几个视频。如果免费积分耗尽，付费标准为 0.01 美元 / 积分，也就是生成一个视频需要 0.2 美元。*2023-07-25 13:24* *机器之心 发表于北京*

* [Gen-2颠覆AI生成视频，一句话秒出4K高清大片，网友：彻底改变游戏规则-36氪](https://36kr.com/p/2501983674115975)

* [只要输入一段话就能生成视频？Gen-2实测\_精彩视频为您呈现\_36氪](https://36kr.com/video/2307964668027272)

* [图像涂哪就动哪，Gen-2新功能“神笔马良”爆火，网友：急急急-36氪](https://36kr.com/p/2515454214115330)

* [视频生成AI卷起来了，一句话一张图就能出大片-虎嗅网](https://m.huxiu.com/article/2054357.html)

* [Runway (@runwayml) / X](https://twitter.com/runwayml)

* [Generative AI’s Next Frontier Is Video - Bloomberg --- 生成式人工智能的下一个前沿领域是视频 - Bloomberg](https://www.bloomberg.com/news/articles/2023-03-20/generative-ai-s-next-frontier-is-video)

* [Runway Gen-2 Update Brings Striking Improvements to AI Video Fidelity and Realism --- Runway Gen-2 更新为 AI 视频保真度和真实度带来了显着改进](https://www.maginative.com/article/runway-gen-2-video-ai-takes-major-step-forward-in-fidelity-and-length/)



Runway Gen-1

Website: https://research.runwayml.com/gen1

About: https://research.runwayml.com/about

Paper:* [[2302.03011] Structure and Content-Guided Video Synthesis with Diffusion Models --- [2302.03011]具有扩散模型的结构和内容引导视频合成](https://arxiv.org/abs/2302.03011)

Gen-1 Explained：

Gen 1 is able to realistically and consistently apply the composition and style of an image or text prompt to the target video allowing you to generate new video content using an existing video.We call this approach video to video, and we're incredibly excited to share a few early use casesstylization mode, transfer the style of any image or prompt to every frame of your video storyboard mode, turn mockups into fully stylized and animated rendersmask mode, isolate subjects in your video and modify them with simple text prompts.Render mode, turn untextured renders into realistic outputs by applying an input imageor prompt.
To realizing the future of storytelling.

Gen 1 能够逼真且一致地将图像或文本提示的构图和样式应用于目标视频，从而允许您使用现有视频生成新的视频内容。我们将这种方法称为视频到视频，我们非常高兴地分享一些早期的用例风格化模式，将任何图像或提示的样式传输到视频故事板模式的每一帧，将模型转换为完全风格化和动画渲染蒙版模式，隔离视频中的主题并使用简单的文本提示对其进行修改。渲染模式，通过应用输入图像或提示将无纹理渲染转换为逼真的输出。
实现讲故事的未来。



3、WonderJourney

项目及演示：https://kovenyu.com/wonderjourney/
论文：https://arxiv.org/pdf/2312.03884.pdf
GitHub：https://github.com/KovenYu/WonderJourney（Coming soon!）

WonderJourney：是一个由斯坦福大学和谷歌合作开发的项目。

它能够根据用户提供的文本描述或图片，**自动生成一系列3D场景的连续画面。**

这些场景不仅多样化，而且**彼此之间还能紧密衔接**，形成一种**虚拟的“奇妙旅程”场景**。

**而且你只需要输入一段描述或上传一张图片即可...**



**主要功能特点：**

与之前专注于单一场景类型的视图生成工作不同，WonderJourney从任何用户提供的位置（通过文本描述或图像）开始，生成一系列多样化但连贯相连的3D场景。

**1、从任意位置出发：**用户可以通过提供一段文本描述或一张图片来指定一个起始点。基于这个起始点WonderJourney将生成一系列3D场景。

例如，如果用户上传一张森林的图片或描述一个城市景观，WonderJourney会从这个场景开始，创造一连串与之相关的3D场景。

**2、长时间的“奇妙之旅”：**WonderJourney能够生成不仅多样化而且持续较长时间的3D场景序列。

用户可以体验一段长时间的虚拟旅程，其中场景会连续不断地变化，提供丰富的视觉体验。

**3、多样化的目的地：**即使从同一个起始点出发，WonderJourney也能生成通往不同“目的地”的多条“奇妙之旅”。

例如，从同一张森林图片出发，一条旅程可能以山脉为终点，而另一条可能以海滩结束，展现出不同的场景和风格。

**4、受控的“奇妙之旅”：**用户可以通过提供一系列文本描述（如诗歌、俳句或故事摘要）来指导生成的旅程。

这允许用户创造更具个性和主题性的旅程。例如，根据一首诗的情感和意象，生成一系列与之相匹配的场景。



**工作原理：**

该框架利用大语言模型（LLM）生成场景的文本描述，一个由文本驱动的点云生成管道来制作引人入胜且连贯的3D场景序列，以及一个视觉语言模型（VLM）来验证生成的场景。

1、场景描述生成：使用大型语言模型（LLM）自动生成场景描述。根据用户输入的文本或图像，LLM提供场景的语义和概念描述。

2、文本驱动的视觉场景生成：根据LLM生成的场景描述，使用文本驱动的视觉场景生成模块创建3D场景。该模块将文本描述转换为彩色点云，形成3D场景。

3、视觉验证：使用视觉语言模型（VLM）对生成的场景进行检查。确保场景没有不希望的视觉效果，如视觉上的错误或不连贯性。

4、连贯性和多样性：生成的3D场景在视觉上连贯，同时在风格和类型上多样化。形成一种连续的视觉旅程，模拟在一个虚拟“奇妙世界”中的体验。

* [小互 on X: "WonderJourney：是一个由斯坦福大学和谷歌合作开发的项目。 它能够根据用户提供的文本描述或图片，自动生成一系列3D场景的连续画面。 这些场景不仅多样化，而且彼此之间还能紧密衔接，形成一种虚拟的“奇妙旅程”场景。 而且你只需要输入一段描述或上传一张图片即可... 主要功能特点：… https://t.co/gptrWSyWBz" / X](https://twitter.com/xiaohuggg/status/1733779657722622449)
  * 发表于2023-12-10 17:24 




* [WonderJourney谷歌合作的 3D 场景生成, 带你走进“奇妙旅程”](https://mp.weixin.qq.com/s?search_click_id=12501261693348582618-1702361382506-3224040202&__biz=Mzg2ODk4MDUxOQ==&mid=2247485556&idx=1&sn=b71b69562cab374580961cd61e05b976#rd)
  * 给定诗歌或故事提要等一系列文本描述,WonderJourney也可以生成古诗词场景。



4、Text-to-Video Tool（Create mini AI videos from text）

URL： [TextToVideo | Create videos from text](https://text-to-video.vercel.app/)

Newsletter Post Title：ChatGPT business ideas with a billionaire

Newsletter Post URL：https://bensbites.beehiiv.com/p/government-bans-will-ai-emerge-victorious

Date：2023年4月3日

This link leads to a website that offers a text-to-video tool. Users can input text and the tool will generate a video based on the content. The website also offers customization options for the video's appearance and background music.

此链接指向一个提供文本转视频工具的网站。用户可以输入文本，该工具将根据内容生成视频。该网站还提供视频外观和背景音乐的自定义选项。

来自 Airtable - Grid view AI Project Tracker 人工智能项目追踪器 Ben's Bites 中提到的所有链接的数据库。https://airtable.com/appuMJo2TCnijMLkz/shrbLgcCayYdxucC7/tblcTEsr9aeCYdIRw

* [Text to Video AI - Product Information, Latest Updates, and Reviews 2023 | Product Hunt --- 文本转视频 AI - 2023 年产品信息、最新更新和评论 |产品搜索](https://www.producthunt.com/products/text-to-video-ai)

  * Text to Video AI 文本转视频人工智能

  * Launched on March 31st, 2023

    Text to Video is my latest project, which allows you to create videos using AI. Currently AI videos are in their "monstrous stage", just like Dalle 2 MINI a while back. The project seeks that people can have a first approach to text-to-video.
    文本到视频是我的最新项目，它允许您使用人工智能创建视频。目前人工智能视频正处于“怪物阶段”，就像不久前的 Dalle 2 MINI 一样。该项目旨在让人们能够拥有第一种将文本转为视频的方法。







先不管 

Imagen Video

A New Text-Conditioned Video Diffusion Model

一种新的文本条件视频扩散模型



Logging

20231213 Jack Lee 今天目标完成500词，最终推进到了4509词

今天主要增加了Gen-1部分和Gen-1 Explained、Gen-2 Explained，Text-to-Video Tool

主要思路是借助https://github.com/OpenMindClub/awesome-chatgpt/tree/main#general 中的

- [Find AI Tools Using AI](https://theresanaiforthat.com/?message=subscribed) - AI tools. Updated daily.
  使用 AI 查找 AI 工具 - AI 工具。每日更新。

进一步明确关键词为**Video generation**，配合阳志平老师提供的方法：从自己能拿到的最优质的公开数据，掌握的最优质的信息入手，我由此联想到我拥有**Ben's Bites**两个每天更新的数据库的访问权限，于是分别在以下两个数据库中用关键词**Video generation**进行搜索，在表格里面用关键词**Video generation**进行过滤搜索（Filtered by Tags），然后完成了今天的500词。

We have two databases that are updated every day;
我们有两个每天更新的数据库；

All 10k+ links we’ve covered, easily filterable
我们涵盖的所有 10k+ 链接都可轻松过滤

6k+ AI company funding rounds from Jan 2022, including investors, amounts, stage etc
2022年1月起超过6k+轮AI公司融资，包括投资者、金额、阶段等

数据库1：Airtable - Grid view AI Project Tracker 人工智能项目追踪器 Ben's Bites 中提到的所有链接的数据库。可过滤和可搜索。包括相关的筹款和投资者数据。

> It includes all links mentioned in the emails, from the first issue. It'll keep updating over time.
>
> 它包括电子邮件中提到的从第一期开始的所有链接。它将随着时间的推移不断更新。

https://airtable.com/appuMJo2TCnijMLkz/shrbLgcCayYdxucC7/tblcTEsr9aeCYdIRw

数据库2：Airtable - Funding Rounds AI Funding Rounds 人工智能融资轮次 人工智能领域所有公司融资轮次的最新数据库 https://airtable.com/appLPuy8wEZ8dbiHI/shrNYsG0mStB7NY06/tblBbns8QETdkqrXC

> The database contains of all AI company funding rounds, the amounts, location, investors and much more.
>
> We populate the information where possible but as with private company data, it may be inaccurate or missing, unfortunately. We verify the data from Crunchbase, Pitchbook and other sources where possible.
>
> 该数据库包含所有人工智能公司的融资回合、金额、地点、投资者等信息。
>
> 我们尽可能填充信息，但遗憾的是，与私人公司数据一样，这些信息可能不准确或丢失。我们尽可能从 Crunchbase, Pitchbook 和其他来源核实数据。

202312121246 Jack Lee 今天搬运* [OpenMindClub/awesome-chatgpt: ⚡ Everything about ChatGPT --- OpenMindClub/awesome-chatgpt：⚡ 关于 ChatGPT 的一切](https://github.com/OpenMindClub/awesome-chatgpt/tree/main#general)的README.md&README.zh-cn.md文件并稍作初步修改，然后在List  about the current collection of AI video projects.md中继续增加字数，增加了元资源中维基百科中文本到视频模型词条和生成式人工智能词条，进一步完善了Pika、Gen-2、WonderJourney的介绍 目前字数2771词

202312112138 Jack Lee init 今天完成初稿500词 20000字/42天=477字/天